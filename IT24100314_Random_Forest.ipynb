{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO02dAl6gLpB"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# IT24100314 - Random Forest Model for Diabetes Prediction\n",
        "# ====================================================================\n",
        "# Main part 1 (setup)\n",
        "# --- 1. Import Necessary Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Load the Preprocessed and Feature-Selected Data ---\n",
        "# These are the final output files from our group's preprocessing pipeline.\n",
        "\n",
        "X_train = pd.read_csv('final_selected_X_train.csv')\n",
        "y_train = pd.read_csv('final_y_train.csv').values.ravel()\n",
        "\n",
        "X_test = pd.read_csv('final_selected_X_test.csv')\n",
        "y_test = pd.read_csv('final_y_test.csv').values.ravel()\n",
        "\n",
        "print(\"\\nData loaded successfully.\")\n",
        "print(f\"Training Features Shape: {X_train.shape}\")\n",
        "print(f\"Training Target Shape:   {y_train.shape}\")\n",
        "print(f\"\\nTesting Features Shape:  {X_test.shape}\")\n",
        "print(f\"Testing Target Shape:    {y_test.shape}\")\n",
        "\n",
        "# Verify the features being used\n",
        "print(\"\\nFeatures selected for modeling:\")\n",
        "print(X_train.columns.tolist())"
      ],
      "metadata": {
        "id": "VJCsiJGok8pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Model Suitability: Why Random Forest?\n",
        "\n",
        "For this diabetes prediction task, I have selected the **Random Forest Classifier**. This is an ensemble learning method that builds multiple decision trees during training and merges their predictions.\n",
        "\n",
        "This model is highly suitable for our problem for several key reasons:\n",
        "\n",
        "*   **High Accuracy:** It is known for its strong predictive performance on complex, tabular datasets like ours.\n",
        "*   **Robust to Overfitting:** By averaging the results of many trees, it is less likely to overfit to the training data compared to a single decision tree.\n",
        "*   **Handles Non-linear Relationships:** It can effectively capture complex interactions between features (e.g., how age and BMI together influence diabetes risk).\n",
        "*   **Provides Feature Importance:** It can rank features by their contribution to the prediction, giving us valuable insights into the key drivers of diabetes in our dataset."
      ],
      "metadata": {
        "id": "FEtkn4GPlfxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Variation 1: Base Random Forest Model ---\n",
        "print(\"--- Training Variation 1: Base Model with 5-Fold Cross-Validation ---\")\n",
        "\n",
        "# a. Initialize the model with default parameters\n",
        "# We set 'random_state=42' to ensure the results are reproducible every time we run the code.\n",
        "base_rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# b. Evaluate using 5-fold Cross-Validation\n",
        "# This is a robust method to estimate the model's performance on the training data.\n",
        "# 'scoring='f1_macro'' is used because the F1-score is a good balance between\n",
        "# precision and recall, which is important for medical diagnoses.\n",
        "cv_scores_f1 = cross_val_score(base_rf, X_train, y_train, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(f\"\\nIndividual F1 Scores for each of the 5 Folds: {cv_scores_f1}\")\n",
        "print(f\"Average F1 Score (Cross-Validation): {np.mean(cv_scores_f1):.4f}\")\n",
        "print(f\"Standard Deviation of F1 Scores: {np.std(cv_scores_f1):.4f}\")"
      ],
      "metadata": {
        "id": "PskNsBxDlgpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Variation 2: Tuned Random Forest Model using GridSearchCV ---\n",
        "print(\"\\n--- Training Variation 2: Hyperparameter Tuning with GridSearchCV ---\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# a. Define the parameter grid to search\n",
        "# These are some of the most important hyperparameters for a Random Forest.\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],         # How many trees to build in the forest.\n",
        "    'max_depth': [10, 20],              # The maximum depth of each tree.\n",
        "    'min_samples_split': [2, 5],        # The minimum number of samples required to split a node.\n",
        "    'min_samples_leaf': [1, 2]          # The minimum number of samples required at a leaf node.\n",
        "}\n",
        "\n",
        "# b. Initialize the GridSearchCV object\n",
        "# This will test all combinations of the parameters in the grid.\n",
        "# We are still optimizing for the 'f1_macro' score.\n",
        "# cv=3 means we use 3-fold cross-validation during the search for speed.\n",
        "# n_jobs=-1 uses all available CPU cores to speed up the process.\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3,\n",
        "                           scoring='f1_macro',\n",
        "                           verbose=1,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# c. Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# d. Display the best parameters found\n",
        "print(f\"\\nBest parameters found by GridSearchCV: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation F1 score during search: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# e. Get the best model from the search\n",
        "best_rf = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "6OVdtfzamJjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Evaluate the Tuned Model (Variation 2) ---\n",
        "print(\"\\n--- Evaluating the Tuned Model with 5-Fold Cross-Validation ---\")\n",
        "\n",
        "# Use the same 5-fold CV method as the base model for a fair comparison\n",
        "tuned_cv_scores_f1 = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(f\"\\nTuned Model 5-Fold CV F1 Scores: {tuned_cv_scores_f1}\")\n",
        "print(f\"Average F1 Score (Tuned Model): {np.mean(tuned_cv_scores_f1):.4f}\")\n",
        "print(f\"Standard Deviation of F1 Scores: {np.std(tuned_cv_scores_f1):.4f}\")"
      ],
      "metadata": {
        "id": "gUtmbf9mnO63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Variation 3: Tuned Model on IMBALANCED Data (Simplified) ---\n",
        "print(\"\\n--- Training Variation 3: Evaluating Impact of Balancing ---\")\n",
        "print(\"This variation uses the training data BEFORE the undersampling step.\")\n",
        "\n",
        "# a. Load the imbalanced (but outlier-handled) training data\n",
        "df_imbalanced = pd.read_csv('IT24100239_Outlier_handling.csv')\n",
        "\n",
        "X_train_imbalanced = df_imbalanced.drop('diabetes', axis=1)\n",
        "y_train_imbalanced = df_imbalanced['diabetes'].values.ravel()\n",
        "\n",
        "# b. Scale this imbalanced data using a NEW scaler fitted ONLY to it\n",
        "# (This simulates the scaling step being done on imbalanced data)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "imbalanced_scaler = MinMaxScaler()\n",
        "columns_to_scale = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "X_train_imbalanced_scaled = X_train_imbalanced.copy()\n",
        "X_train_imbalanced_scaled[columns_to_scale] = imbalanced_scaler.fit_transform(X_train_imbalanced[columns_to_scale])\n",
        "\n",
        "\n",
        "print(f\"\\nImbalanced training data shapes: X={X_train_imbalanced_scaled.shape}, y={y_train_imbalanced.shape}\")\n",
        "print(\"Class distribution in the imbalanced training data:\")\n",
        "print(pd.Series(y_train_imbalanced).value_counts())\n",
        "\n",
        "# c. Evaluate your BEST model (best_rf) on this imbalanced data\n",
        "imbalanced_cv_scores_f1 = cross_val_score(best_rf, X_train_imbalanced_scaled, y_train_imbalanced, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(f\"\\nTuned Model on Imbalanced Data (5-Fold CV F1 Scores): {imbalanced_cv_scores_f1}\")\n",
        "print(f\"Average F1 Score on Imbalanced Data: {np.mean(imbalanced_cv_scores_f1):.4f}\")"
      ],
      "metadata": {
        "id": "ijKDJaMgtKjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Final Evaluation on the Unseen Test Set ---\n",
        "# We use our BEST model (the tuned 'best_rf' from Variation 2) and evaluate its performance\n",
        "# on the independent, scaled test data (X_test, y_test).\n",
        "\n",
        "print(\"\\n--- Final Model Evaluation on Test Data ---\")\n",
        "\n",
        "# a. Make predictions on the test set\n",
        "y_pred = best_rf.predict(X_test)\n",
        "y_pred_proba = best_rf.predict_proba(X_test)[:, 1] # Probabilities needed for AUC\n",
        "\n",
        "# b. Print the core evaluation metrics\n",
        "print(\"1. Key Metrics (Precision, Recall, F1-Score, Support):\")\n",
        "# The classification report is the most detailed metric output.\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# c. Print AUC Score (Area Under the ROC Curve)\n",
        "print(f\"\\n2. AUC Score (Overall Model Discriminative Power): {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "\n",
        "# d. Create the Confusion Matrix Visualization (Required EDA/Visual)\n",
        "print(\"\\n3. Confusion Matrix Visualization:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No Diabetes (0)', 'Predicted Diabetes (1)'],\n",
        "            yticklabels=['Actual No Diabetes (0)', 'Actual Diabetes (1)'])\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('Actual Class')\n",
        "plt.title(f'Confusion Matrix - Random Forest (Test Set) \\n AUC: {roc_auc_score(y_test, y_pred_proba):.4f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TUkE9mgptwpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Conclusion, Comparison, and Recommendations\n",
        "\n",
        "### Comparison of Model Varieties:\n",
        "\n",
        "| Variation | Tuning/Balancing | Validation Method | Average F1-Macro Score (Training) |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **1 (Base Random Forest)** | No Tuning | 5-Fold Cross-Validation | **0.8981** |\n",
        "| **2 (Tuned Random Forest)**| GridSearchCV Tuning | 5-Fold Cross-Validation | **0.9067** |\n",
        "| **3 (Tuned RF on Imbalanced)**| Tuned, No Balancing | 5-Fold Cross-Validation | **0.8928** |\n",
        "\n",
        "### Insights and Conclusion:\n",
        "\n",
        "1.  **Impact of Hyperparameter Tuning:** Optimizing the model's parameters with GridSearchCV improved the average F1-score from 0.8981 to **0.9067**. This demonstrates that tuning parameters like `max_depth` and `n_estimators` leads to a more robust and accurate model.\n",
        "2.  **Importance of Preprocessing (Balancing):** Training the model on the imbalanced data resulted in a lower F1-score of 0.8928. This proves that the **undersampling step was critical** for building a model that performs well for both diabetic and non-diabetic classes, ensuring fairness.\n",
        "3.  **Final Model Choice:** The **Tuned Random Forest Classifier (Variation 2)** is the optimal model from the training phase, as it achieved the highest cross-validated F1-score.\n",
        "\n",
        "---\n",
        "\n",
        "### **Final Performance on Unseen Test Set:**\n",
        "\n",
        "This is the true performance of our best model on the independent test data, which was kept separate throughout the process.\n",
        "\n",
        "*   **Overall Accuracy:** **90%**\n",
        "*   **Diabetes (Class 1) F1-Score:** **0.61**\n",
        "*   **AUC Score:** **0.9765**\n",
        "\n",
        "### **Analysis of the Confusion Matrix and Metrics:**\n",
        "\n",
        "The **Confusion Matrix** provides a clear picture of the model's performance in a real-world scenario:\n",
        "\n",
        "*   **True Positives (Correctly Identified Diabetics):** The model successfully identified **1,553** patients who truly have diabetes.\n",
        "*   **False Negatives (Missed Diabetic Patients):** The model incorrectly classified **147** diabetic patients as not having diabetes. This is the most critical error in a medical context.\n",
        "*   **True Negatives:** **16,444** non-diabetic individuals were correctly identified.\n",
        "*   **False Positives:** **1,853** non-diabetic individuals were incorrectly flagged as having diabetes.\n",
        "\n",
        "**Insights from Precision and Recall:**\n",
        "*   Our model has an excellent **Recall of 0.91** for the diabetes class. This means it successfully **found 91% of all the actual diabetic patients** in the test set, which is extremely good for a screening tool.\n",
        "*   The **Precision is 0.46**, which means that when the model"
      ],
      "metadata": {
        "id": "sazDsWJtuPvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Interactive Prediction UI (FINAL ROBUST VERSION) ---\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- 1. Create the Scaler CORRECTLY ---\n",
        "# We fit the scaler ONCE on the UN-SCALED, outlier-handled training data.\n",
        "# This ensures it learns the true min and max of the data distribution.\n",
        "\n",
        "# Load the unscaled training data (from after outlier handling)\n",
        "df_for_scaling = pd.read_csv('IT24100239_Outlier_handling.csv')\n",
        "X_train_unscaled = df_for_scaling.drop('diabetes', axis=1)\n",
        "\n",
        "# Define the columns and fit the scaler\n",
        "scaler = MinMaxScaler()\n",
        "columns_to_scale = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "scaler.fit(X_train_unscaled[columns_to_scale])\n",
        "\n",
        "print(\"Scaler has been correctly fitted on the original data distribution.\")\n",
        "\n",
        "\n",
        "# --- 2. Create the UI Widgets ---\n",
        "# (This part is unchanged)\n",
        "print(\"\\nPlease input the patient's details below and click 'Predict'.\")\n",
        "\n",
        "gender_widget = widgets.Dropdown(options=['Female', 'Male'], description='Gender:')\n",
        "smoking_widget = widgets.Dropdown(options=['never', 'former', 'No Info', 'current', 'not current', 'ever'], description='Smoking History:')\n",
        "hypertension_widget = widgets.Dropdown(options=[('No', 0), ('Yes', 1)], description='Hypertension:')\n",
        "heart_disease_widget = widgets.Dropdown(options=[('No', 0), ('Yes', 1)], description='Heart Disease:')\n",
        "age_widget = widgets.IntSlider(value=40, min=1, max=80, step=1, description='Age:')\n",
        "bmi_widget = widgets.FloatSlider(value=27.0, min=10.0, max=50.0, step=0.1, description='BMI:')\n",
        "hba1c_widget = widgets.FloatSlider(value=5.5, min=3.0, max=9.0, step=0.1, description='HbA1c Level:')\n",
        "glucose_widget = widgets.IntSlider(value=120, min=80, max=300, step=5, description='Glucose Level:')\n",
        "predict_button = widgets.Button(description=\"Predict Diabetes Status\", button_style='success')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "\n",
        "# --- 3. Define the Button Click Logic ---\n",
        "# This function will now use the scaler that was correctly fitted above.\n",
        "\n",
        "def on_predict_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "\n",
        "        # Build the feature dictionary from UI widgets\n",
        "        feature_dict = {col: 0 for col in X_train.columns} # Use final X_train columns as template\n",
        "\n",
        "        feature_dict['age'] = age_widget.value\n",
        "        feature_dict['hypertension'] = hypertension_widget.value\n",
        "        feature_dict['heart_disease'] = heart_disease_widget.value\n",
        "        feature_dict['bmi'] = bmi_widget.value\n",
        "        feature_dict['HbA1c_level'] = hba1c_widget.value\n",
        "        feature_dict['blood_glucose_level'] = glucose_widget.value\n",
        "\n",
        "        # Handle gender (checking if it was a selected feature)\n",
        "        if 'gender_encoded' in X_train.columns:\n",
        "             feature_dict['gender_encoded'] = 1 if gender_widget.value == 'Male' else 0\n",
        "\n",
        "        # Handle selected smoking features\n",
        "        smoking_status = smoking_widget.value\n",
        "        if 'smoking_former' in X_train.columns and smoking_status == 'former':\n",
        "            feature_dict['smoking_former'] = 1\n",
        "        if 'smoking_never' in X_train.columns and smoking_status == 'never':\n",
        "            input_data['smoking_never'] = 1\n",
        "\n",
        "        # Create DataFrame from the dictionary\n",
        "        patient_df = pd.DataFrame([feature_dict])\n",
        "\n",
        "        # NOW, scale the new data using the CORRECTLY fitted scaler\n",
        "        patient_df[columns_to_scale] = scaler.transform(patient_df[columns_to_scale])\n",
        "\n",
        "        # The DataFrame is now correctly preprocessed and ordered\n",
        "        final_patient_df = patient_df[X_train.columns]\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = best_rf.predict(final_patient_df)\n",
        "        prediction_proba = best_rf.predict_proba(final_patient_df)\n",
        "\n",
        "        if prediction[0] == 1:\n",
        "            result_text = \"Positive for Diabetes\"\n",
        "            confidence = prediction_proba[0][1]\n",
        "        else:\n",
        "            result_text = \"Negative for Diabetes\"\n",
        "            confidence = prediction_proba[0][0]\n",
        "\n",
        "        result_string = f\"Prediction: {result_text} (Confidence: {confidence:.2%})\"\n",
        "\n",
        "        print(\"--- Prediction Result ---\")\n",
        "        print(result_string)\n",
        "\n",
        "# --- 4. Display the UI and Attach the Logic ---\n",
        "ui = widgets.VBox([\n",
        "    widgets.HBox([age_widget, bmi_widget]),\n",
        "    widgets.HBox([hba1c_widget, glucose_widget]),\n",
        "    widgets.HBox([gender_widget, smoking_widget]),\n",
        "    widgets.HBox([hypertension_widget, heart_disease_widget]),\n",
        "    predict_button,\n",
        "    output_area\n",
        "])\n",
        "display(ui)\n",
        "predict_button.on_click(on_predict_button_clicked)"
      ],
      "metadata": {
        "id": "lSyoenQK2vGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}